{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# Options for pandas\n",
    "pd.options.display.max_columns = 150\n",
    "pd.options.display.max_rows = 150"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Introduction</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Imports\" data-toc-modified-id=\"Imports-1.0.1\"><span class=\"toc-item-num\">1.0.1&nbsp;&nbsp;</span>Imports</a></span></li></ul></li></ul></li><li><span><a href=\"#Challenge\" data-toc-modified-id=\"Challenge-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Challenge</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You now have a fairly substantial starting toolbox of supervised learning methods that you can use to tackle a host of exciting problems. To make sure all of these ideas are organized in your mind, please go through the list of problems below. For each, identify which supervised learning method(s) would be best for addressing that particular problem. Explain your reasoning and discuss your answers with your mentor.\n",
    "\n",
    "1. Predict the running times of prospective Olympic sprinters using data from the last 20 Olympics.\n",
    "    - Output is continuous so it's either linear regression or KNN regression. All Olympic sprinters probably have similar features in terms of physical dimensions so the most important feature would probably be the sprinter's  running time rate of improvement (e.g. rate in which their running time improved over the course of last month) and how consistent they meet their PR. It's doesn't mean that runners with similar rate of improvement and consistent PR frequency will have similar running times so KNN regression would not work. \n",
    "    \n",
    "    \n",
    "2. You have more features (columns) than rows in your dataset.\n",
    "    - Depends on the target variable and correlation of features with target variable. If there are multiple correlated features then a random forrest. If not then linear regression with L1 regularizations. Since there are many features, L1 regularization will push non important features to zero.\n",
    "    \n",
    "3. Identify the most important characteristic predicting likelihood of being jailed before age 20.\n",
    "    - Decision tree since it does feature selection by selecting features with the lowest entropy or uncertainity. Gradient boosting classifier since the model has an attribute that highlights which features are most important in predicting the target outcome. If the characteristics are independent from one another then Naive Bayes. \n",
    "    \n",
    "    \n",
    "4. Implement a filter to “highlight” emails that might be important to the recipient\n",
    "    - Since it's a binary classification problem and little data is required, I would say Naive Bayes.\n",
    "    \n",
    "5. You have 1000+ features.\n",
    "    - If the target variable is continous, linear regression with L1 regularization. The same reason why stated in question 2.\n",
    "    \n",
    "6. Predict whether someone who adds items to their cart on a website will purchase the items.\n",
    "    - Decision Tree/Random Forrest or KNN. If all features are numeric then either would work. If data includes categorical features then decision tree/random forrest. If a person want to dissect and comprehend the inner workings of the model then the decision tree would be the best. \n",
    "    \n",
    "    \n",
    "7. Your dataset dimensions are 982400 x 500\n",
    "    - Depends on the target variable. If it's continous then linear regression with L1 regularization. If the data includes non-linearity and multicollinearity then SVM, or sometype of boosting model such as random forrest. \n",
    "    \n",
    "8. Identify faces in an image.\n",
    "    - CNN with data augmentation since it will be able to indentify high level facial patterns and accuratly predict faces.\n",
    "    \n",
    "9. Predict which of three flavors of ice cream will be most popular with boys vs girls.\n",
    "    - Naive Bayes since the target outcome is a probability and there are a small amount of features needed to make the prediction. The features used are probably independent from one another. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
