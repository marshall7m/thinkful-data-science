{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "try different manufacturer/model name thresholds\n",
    "combine manufacturer/model name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "from nltk.corpus import stopwords\n",
    "import time\n",
    "from collections import Counter\n",
    "\n",
    "from scipy.stats import bartlett, levene, boxcox, shapiro\n",
    "from scipy.stats.mstats import winsorize\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LinearRegression, LassoCV, ElasticNetCV, RidgeCV, Lasso, Ridge, ElasticNet\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_validate, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from statsmodels.tools.eval_measures import mse, rmse\n",
    "\n",
    "# Options for pandas\n",
    "pd.options.display.max_columns = 150\n",
    "pd.options.display.max_rows = 150"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Introduction</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Imports\" data-toc-modified-id=\"Imports-1.0.1\"><span class=\"toc-item-num\">1.0.1&nbsp;&nbsp;</span>Imports</a></span></li></ul></li></ul></li><li><span><a href=\"#Import-Data\" data-toc-modified-id=\"Import-Data-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Import Data</a></span></li><li><span><a href=\"#Dataset-Description\" data-toc-modified-id=\"Dataset-Description-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Dataset Description</a></span></li><li><span><a href=\"#Null-Values\" data-toc-modified-id=\"Null-Values-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Null Values</a></span></li><li><span><a href=\"#Explanatory-Features-Visualizations\" data-toc-modified-id=\"Explanatory-Features-Visualizations-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Explanatory Features Visualizations</a></span></li><li><span><a href=\"#Explanatory-vs.-Target-Variable-Visualizations\" data-toc-modified-id=\"Explanatory-vs.-Target-Variable-Visualizations-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Explanatory vs. Target Variable Visualizations</a></span></li><li><span><a href=\"#Cleaning\" data-toc-modified-id=\"Cleaning-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Cleaning</a></span><ul class=\"toc-item\"><li><span><a href=\"#Condition-Mapping\" data-toc-modified-id=\"Condition-Mapping-7.1\"><span class=\"toc-item-num\">7.1&nbsp;&nbsp;</span>Condition Mapping</a></span></li><li><span><a href=\"#Manufacturer/Model-Name\" data-toc-modified-id=\"Manufacturer/Model-Name-7.2\"><span class=\"toc-item-num\">7.2&nbsp;&nbsp;</span>Manufacturer/Model Name</a></span></li></ul></li><li><span><a href=\"#Target-Variable-Visualization\" data-toc-modified-id=\"Target-Variable-Visualization-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Target Variable Visualization</a></span></li><li><span><a href=\"#Target-Variable-Outliers\" data-toc-modified-id=\"Target-Variable-Outliers-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>Target Variable Outliers</a></span><ul class=\"toc-item\"><li><span><a href=\"#One-Hot-Encoded-Description-Words\" data-toc-modified-id=\"One-Hot-Encoded-Description-Words-9.1\"><span class=\"toc-item-num\">9.1&nbsp;&nbsp;</span>One-Hot Encoded Description Words</a></span></li><li><span><a href=\"#One-Hot-Encoded-Features\" data-toc-modified-id=\"One-Hot-Encoded-Features-9.2\"><span class=\"toc-item-num\">9.2&nbsp;&nbsp;</span>One-Hot Encoded Features</a></span></li><li><span><a href=\"#Initialize-Modeling-Dataframe\" data-toc-modified-id=\"Initialize-Modeling-Dataframe-9.3\"><span class=\"toc-item-num\">9.3&nbsp;&nbsp;</span>Initialize Modeling Dataframe</a></span></li><li><span><a href=\"#Multicollinearity\" data-toc-modified-id=\"Multicollinearity-9.4\"><span class=\"toc-item-num\">9.4&nbsp;&nbsp;</span>Multicollinearity</a></span></li></ul></li><li><span><a href=\"#Modeling\" data-toc-modified-id=\"Modeling-10\"><span class=\"toc-item-num\">10&nbsp;&nbsp;</span>Modeling</a></span></li><li><span><a href=\"#Evaluate-Best-Model\" data-toc-modified-id=\"Evaluate-Best-Model-11\"><span class=\"toc-item-num\">11&nbsp;&nbsp;</span>Evaluate Best Model</a></span><ul class=\"toc-item\"><li><span><a href=\"#Evaluating-Coefficients\" data-toc-modified-id=\"Evaluating-Coefficients-11.1\"><span class=\"toc-item-num\">11.1&nbsp;&nbsp;</span>Evaluating Coefficients</a></span></li></ul></li><li><span><a href=\"#Improvements\" data-toc-modified-id=\"Improvements-12\"><span class=\"toc-item-num\">12&nbsp;&nbsp;</span>Improvements</a></span><ul class=\"toc-item\"><li><span><a href=\"#Dataset\" data-toc-modified-id=\"Dataset-12.1\"><span class=\"toc-item-num\">12.1&nbsp;&nbsp;</span>Dataset</a></span></li><li><span><a href=\"#Modeling\" data-toc-modified-id=\"Modeling-12.2\"><span class=\"toc-item-num\">12.2&nbsp;&nbsp;</span>Modeling</a></span></li></ul></li><li><span><a href=\"#Application-and-End-User-Value\" data-toc-modified-id=\"Application-and-End-User-Value-13\"><span class=\"toc-item-num\">13&nbsp;&nbsp;</span>Application and End User Value</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/clean_data/clean_board_source_data.json') as datafile:\n",
    "    data = json.load(datafile)\n",
    "board_source_df = pd.DataFrame(data)\n",
    "\n",
    "with open('data/clean_data/clean_usb_data.json') as datafile:\n",
    "    data = json.load(datafile)\n",
    "usb_df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "board_source_df = board_source_df.reset_index(drop=True)\n",
    "usb_df = usb_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = board_source_df.append(usb_df, sort=True)\n",
    "\n",
    "print('Original Count', len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset consist of surfboards ads scraped from two online surf shop companies. The first surf shop is \"Used Surfboards Hawaii\" from Honolulu, Hawaii. The second company is \"The Board Source\" from Carlsbad, California. The features of the dataset are: condition, description, manufacturer, model name, board dimensions (height, width, and thickness), and sale price."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Null Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two observations with null condition value. Being that there are only two cases, it's safe to just drop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.isnull().sum()/df.isnull().count()*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=['condition'], inplace=True)\n",
    "\n",
    "print('Current Count: ', len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop column with string nulls\n",
    "\n",
    "df = df[df['model_name'] != 'nan'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explanatory Features Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(70,40))\n",
    "plt.rcParams.update({'font.size': 50})\n",
    "\n",
    "plt.subplot(2,3,1)\n",
    "plt.title('Manufacturer Distribution')\n",
    "plt.xlabel('Count')\n",
    "manufacturer_name = list(df['manufacturer'].value_counts().keys())[:20]\n",
    "manufacturer_count = list(df['manufacturer'].value_counts().values)[:20]\n",
    "plt.barh(manufacturer_name, manufacturer_count)\n",
    "\n",
    "plt.subplot(2,3,2)\n",
    "plt.title('Model Name Distribution')\n",
    "plt.xlabel('Count')\n",
    "model_name = list(df['model_name'].value_counts().keys())[:20]\n",
    "model_count = list(df['model_name'].value_counts().values)[:20]\n",
    "plt.barh(model_name, model_count)\n",
    "\n",
    "plt.subplot(2,3,3)\n",
    "plt.title('Condition Distribution')\n",
    "plt.xlabel('Count')\n",
    "condition_name = list(df['condition'].value_counts().keys())[:20]\n",
    "condition_count = list(df['condition'].value_counts().values)[:20]\n",
    "plt.barh(condition_name, condition_count)\n",
    "\n",
    "plt.subplot(2,3,4)\n",
    "plt.title('Height')\n",
    "plt.xlabel('Feet')\n",
    "plt.ylabel('Count')\n",
    "plt.hist(df.height)\n",
    "plt.xticks(np.arange(4,18,1))\n",
    "\n",
    "plt.subplot(2,3,5)\n",
    "plt.title('Width')\n",
    "plt.xlabel('Inches')\n",
    "plt.ylabel('Count')\n",
    "plt.hist(df.width)\n",
    "\n",
    "plt.subplot(2,3,6)\n",
    "plt.title('Thickness')\n",
    "plt.xlabel('Inches')\n",
    "plt.ylabel('Count')\n",
    "plt.hist(df.thickness)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there are 695 unique manufacturer and 1131 unique model names within this dataset, only the top 20 manufacturers and model names are displayed. There's five dominating manufacturers and three dominating model names.\n",
    "\n",
    "As of the board dimension plots, majority of the surfboards are in the shortboard size range. Any board that's longer than 8 feet, wider than 19 to 20 inches, and thicker than three inches are likely to fall under the longboard or SUP (stand-up paddleboard) category. \n",
    "\n",
    "The three dominating model names are considered surfboard tail shapes. Surfboard tail shapes are not necessarily model names but an essential attribute of a surfboard. As you can see below, these particular model names are shared across multiple manufacturers. This will likely result in the regression models to find these general model names to be less important for predicting the surfboard's prices. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Group by top model names and manufacturer count\n",
    "top_model_names = ['squash', 'round', 'swallow']\n",
    "\n",
    "df.loc[(df['model_name'].isin(top_model_names))].groupby(['model_name', 'manufacturer']).size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Group by top manufacturers and top model names count\n",
    "top_manufacturers = ['superbrand', 'firewire', 'lost', 'christenson', 'easy button']\n",
    "\n",
    "df.loc[(df['manufacturer'].isin(top_manufacturers) & df['model_name'].isin(top_model_names))].groupby(['manufacturer', 'model_name']).size()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explanatory vs. Target Variable Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(70,40))\n",
    "plt.rcParams.update({'font.size': 50})\n",
    "\n",
    "plt.subplot(2,2,1)\n",
    "plt.title('Height vs. Price')\n",
    "plt.xlabel('Height (Inches)')\n",
    "plt.ylabel('Price')\n",
    "plt.scatter(df['height'], df['price'])\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plt.title('Width vs. Price')\n",
    "plt.xlabel('Width (Inches)')\n",
    "plt.ylabel('Price')\n",
    "plt.scatter(df['width'], df['price'])\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.title('Thickness')\n",
    "plt.xlabel('Thickness (Inches)')\n",
    "plt.ylabel('Price')\n",
    "plt.scatter(df['thickness'], df['price'])\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "plt.title('Condition vs. Price')\n",
    "sns.violinplot('condition', 'price', data=df, order=['new', 'like_new', 'excellent', 'great', 'good', 'fair', 'poor'])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the scatter plots and correlation coefficient matrix above, there's is a positive correlation between all board dimension features and price. This is especially the case with surfboard that are categorized under longboards or SUP. Longboards and SUPs are usually larger in all aspects. This results in higher material cost compared to smaller surfboards. \n",
    "\n",
    "Within the condition vs. price violin plot, there are large outliers in the new and excellent category. These outliers will be capped in the target variable outliers section below. As with any product, we can see that the better surfboard condition the higher the price. Although in the good condition plot there are boards that are priced higher than surfboards in the great condition and better. This are likely higher end surfboards that hold their value. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Condition Mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The majority of surfboards are in excellent condition while a minority of surfboards are in poor to fair condition. The condition of the surfboard will likely be an important feature for predicting the respective surfboard price. Since like new and excellent are arguably the same and there is a small sample of like new surfboards, like new surfboards will be mapped to the excellent category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['condition'] = df['condition'].apply(lambda x: 'excellent' if x == 'like_new' else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['condition'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manufacturer/Model Name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While interpreting the model's coefficients, I've found that the one-hot encoded manufacturers features were important features for determining price. Less frequent manufacturers surfboards had larger residuals compared to more frequent manufacturer surfboards. To reduce the loss for each model, the cell below filters out manufacturer with surfboard counts below a defined threshold. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['model_name'] = df['model_name'].apply(lambda x: x.replace(' ', '_'))\n",
    "df['manufacturer'] = df['manufacturer'].apply(lambda x: x.replace(' ', '_'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "threshold = 20\n",
    "minority_manufacturer_list = []\n",
    "\n",
    "for manufacturer, count in df.groupby('manufacturer').size().items():\n",
    "    if count <= threshold:\n",
    "        minority_manufacturer_list.append(manufacturer)\n",
    "\n",
    "df['manufacturer'] = df['manufacturer'].apply(lambda x: 'other' if x in minority_manufacturer_list else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 20\n",
    "minority_model_name_list = []\n",
    "\n",
    "for model_name, count in df.groupby('model_name').size().items():\n",
    "    if count <= threshold:\n",
    "        minority_model_name_list.append(model_name)\n",
    "\n",
    "df['model_name'] = df['model_name'].apply(lambda x: 'other' if x in minority_model_name_list else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Target Variable Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 15})\n",
    "\n",
    "plt.title('Price Distribution')\n",
    "plt.xlabel('Price')\n",
    "plt.ylabel('Count')\n",
    "plt.hist(df['price'], bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The surfboard price distribution is skewed right. The distance between the 75th percentile and the max value is very large. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Target Variable Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since regression models are sensitive to outliers, these outliers will either be winsorized or dropped. For th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Previous Count: ', len(df))\n",
    "\n",
    "df = df[df['price'] < 1000].copy()\n",
    "\n",
    "print('Current Count: ', len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#New Distribution\n",
    "plt.rcParams.update({'font.size': 15})\n",
    "\n",
    "plt.title('Price Distribution')\n",
    "plt.xlabel('Price')\n",
    "plt.ylabel('Count')\n",
    "plt.hist(df['price'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-Hot Encoded Description Words\n",
    "\n",
    "One-Hot Encode surfboard terms within the description feature that are strongly correlated with surfboard price. \n",
    "\n",
    "Negatively Correlated Terms:\n",
    "    - Ding/Dent: Dent in surfboard usually causing the surfboard's outer shell (fiberglass) to crack. \n",
    "    - Pressure Ding/Dent: Less severe form of a regular surfboard ding without cracking the fiberglass\n",
    "    - Professionally fixed ding: Ding repair is sanded flush with board (won't cause board to drag), water tight,  and no air bubbles\n",
    "    \n",
    "Positive Correlated Terms:\n",
    "    - SUP (Stand up Paddle Board)\n",
    "    - Longboard (surfboard height >= ~ 8')\n",
    "    - Hydro foil (Google it)\n",
    "    - No dings (no dents)\n",
    "    - Epoxy (Type of material used with surfboard) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#used to create ngrams of description word list\n",
    "def ngram(text, n_gram):\n",
    "    n_gram_list = []\n",
    "    for i in range(len(text)-n_gram):\n",
    "        text_seq = ' '.join(text[i:i+n_gram])\n",
    "        n_gram_list.append(text_seq)\n",
    "    unique_ngram_list = list(np.unique(n_gram_list))\n",
    "    return unique_ngram_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram_list = ['professionally fixed dings', 'professionally fixed ding', 'professionally repaired dings',\n",
    "                'light pressure dents', 'minor pressure denting', 'minimal pressure dents', \n",
    "                'minimal pressure denting','various pressure dents']\n",
    "\n",
    "bigram_list = ['repaired dings', 'repaired ding', 'pressure dents', 'pressure dent', \n",
    "               'nose ding', 'rail ding', 'cracked fin', 'no dings', 'deck patch']\n",
    "\n",
    "unigram_list = ['sup', 'longboard', 'hydrofoil', 'epoxy', 'shortboard', 'fish', 'gun', 'semi-gun', 'funboard']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create tri/bigram columns for matching one hot encoded words in description\n",
    "\n",
    "df['trigram_description_list'] = df['description_word_list'].apply(lambda x: ngram(x, 3))\n",
    "df['bigram_description_list'] = df['description_word_list'].apply(lambda x: ngram(x, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#init df for one-hot encoded description words\n",
    "description_one_hot_df = pd.DataFrame(index=range(len(df)))\n",
    "\n",
    "#ngram words to be one hot encoded\n",
    "gram_nested_list = [unigram_list, bigram_list, trigram_list]\n",
    "\n",
    "#ngram columns to look up gram words\n",
    "column_gram_list = ['description_word_list', 'bigram_description_list', 'trigram_description_list']\n",
    "\n",
    "#init gram dict\n",
    "gram_dict = dict(zip(column_gram_list, gram_nested_list))\n",
    "\n",
    "#loop through gram columns to lookup one hot encoded ngrams\n",
    "for column_gram, gram_list in gram_dict.items():\n",
    "    for i,word_list in enumerate(df[column_gram]):\n",
    "        for gram in gram_list:\n",
    "            if gram in word_list:\n",
    "                underscore_gram = gram.replace(' ', '_')\n",
    "                description_one_hot_df.at[i, 'DV_'+underscore_gram] = 1\n",
    "description_one_hot_df.fillna(0, inplace=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-Hot Encoded Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot columns with single categorical value\n",
    "one_hot_df = pd.get_dummies(df[['condition', 'manufacturer', 'model_name']], drop_first=True).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Modeling Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#columns with continous values\n",
    "continous_df = df[['height', 'width', 'thickness', 'price']].copy()\n",
    "\n",
    "#columns with one-hot description words\n",
    "description_one_hot_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "#create dataframe with features that will be used for modeling\n",
    "\n",
    "model_df = continous_df.join(one_hot_df).join(description_one_hot_df)\n",
    "\n",
    "data_x = model_df[model_df.columns[~model_df.columns.isin(['price'])]]\n",
    "data_y = model_df['price']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multicollinearity "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a strong multicollinearity between manufacturer and model name and between board dimensions. Combined manufacturer and model and board dimensions separately with intention to eliminate multicollinearity but effort resulted in lower performance than with multicollinearity.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize hyperparameters for each model and add metrics results to model results dataframe\n",
    "\n",
    "def model_results(model_list, train_x, train_y, test_x, test_y, x_cols):\n",
    "    \n",
    "    model_dict = []\n",
    "    for name, model in model_list.items():\n",
    "        print(name)\n",
    "        model_metrics = {}\n",
    "        model = GridSearchCV(model, model.parameters, cv=3)\n",
    "        \n",
    "        model.fit(train_x, train_y)\n",
    "            \n",
    "        print(model.best_estimator_)\n",
    "        \n",
    "        pred_y = model.predict(test_x)\n",
    "        \n",
    "        model_metrics['r2'] = model.score(test_x, test_y)\n",
    "        model_metrics['root_MSE'] = np.sqrt(mse(test_y, pred_y))\n",
    "        model_metrics['MAE'] = np.abs(test_y - pred_y).mean()\n",
    "        model_metrics['MAPE'] = (np.abs(test_y - pred_y) / test_y).mean() * 100\n",
    "        model_metrics['model_name'] = name\n",
    "        \n",
    "        \n",
    "        model_dict.append(model_metrics)\n",
    "            \n",
    "    model_results_df = pd.DataFrame(model_dict).set_index('model_name')\n",
    "\n",
    "    return model_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "standard_s = StandardScaler()\n",
    "data_x_cols = data_x.columns\n",
    "normalized_data_x = standard_s.fit_transform(data_x)\n",
    "train_x, test_x, train_y, test_y = train_test_split(normalized_data_x, data_y, test_size=.2)\n",
    "\n",
    "#hyper parameter testing attributes\n",
    "\n",
    "alpha_dict = {'alpha': [.001,.01,.1,1]}\n",
    "\n",
    "elastic = ElasticNet()\n",
    "elastic.parameters = alpha_dict\n",
    "\n",
    "lasso = Lasso()\n",
    "lasso.parameters = alpha_dict\n",
    "\n",
    "ridge = Ridge()\n",
    "ridge.parameters = alpha_dict\n",
    "\n",
    "mlp = MLPRegressor()\n",
    "mlp.parameters = {'hidden_layer_sizes': [(100,), (100,50,)],\n",
    "                  'alpha': [.001,.01,.1,1]}\n",
    "\n",
    "rf = RandomForestRegressor()\n",
    "rf.parameters = {'n_estimators': [10, 50, 100],\n",
    "                 'max_depth': [2,4,8,16],\n",
    "                 'max_features': ['sqrt', 'auto', ],\n",
    "                 'min_samples_split': [2, 4, 8, 16],\n",
    "                 'min_samples_leaf': [1, 2, 4, 8, 16]}\n",
    "\n",
    "svr = SVR()\n",
    "svr.parameters = {'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "                  'C': [1, 10, 100, 1000],\n",
    "                  'gamma': [.001, .01, .1, .5, .9]}\n",
    "\n",
    "model_list = {'elastic': elastic, 'ridge': ridge, 'lasso': lasso, 'mlp': mlp, 'rf': rf, 'svr': svr}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model_results_df = model_results(model_list, train_x, train_y, test_x, test_y, data_x_cols)\n",
    "\n",
    "model_results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best model in regards to all metrics, was the Lasso model (L1 Regularization). In close second was the ElasticNet model and third was the Ridge model. The linear and MLP models' performance was surprisingly poor. \n",
    "\n",
    "use mae to interpret results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lasso = Lasso(alpha=1)\n",
    "lasso.fit(train_x, train_y)\n",
    "pred_y = lasso.predict(test_x)\n",
    "\n",
    "plt.scatter(test_y, pred_y, alpha=.3)\n",
    "plt.plot(test_y, test_y, color='red')\n",
    "plt.title('True Y vs. Predicted Y')\n",
    "plt.xlabel('True Y')\n",
    "plt.ylabel('Predicted Y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_term = pred_y - test_y\n",
    "\n",
    "plt.scatter(pred_y, error_term)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Residual')\n",
    "plt.axhline(y=0)\n",
    "plt.title('Residual vs. Predicted')\n",
    "plt.show()\n",
    "\n",
    "bart_stats = bartlett(pred_y, error_term)\n",
    "lev_stats = levene(pred_y, error_term)\n",
    "\n",
    "print(\"Bartlett t-test: {0:3g} ... P-value: {1:.3g}\".format(bart_stats[0], bart_stats[1]))\n",
    "print(\"Levene t-test: {0:3g} ... P-value: {1:.3g}\".format(lev_stats[0], lev_stats[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Coefficients "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_dict = dict(zip(data_x.columns, lasso.coef_))\n",
    "sorted_coef_dict = sorted(coef_dict.items(), key=lambda kv: kv[1])\n",
    "\n",
    "strongest_coef = dict(sorted_coef_dict[:10])\n",
    "strongest_coef.update(dict(sorted_coef_dict[-10:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.rcParams.update({'font.size': 25})\n",
    "plt.title('Strongest Coeff')\n",
    "plt.barh(list(strongest_coef.keys()), list(strongest_coef.values()))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application and End User Value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Surf Shops:\n",
    "\n",
    "Models would be trained only with data from one surf shop since surf shops will have different opinions on prices. The model can be a feature on the respective surf shop website. With this particular dataset, only surfboads less than $1000 were used for modeling, so the model would be innaccurate for predicting higher end surfboards. \n",
    "\n",
    "Surfboard Seller:\n",
    "\n",
    "Users can enter their surfboard information and use the predicted surfboard price to determine if they want to sell their surfboard at that specific surf shop or use it as a reference price for selling their board at other surf shops. \n",
    "\n",
    "User Experience:\n",
    "\n",
    "User access predictive surfboard price via surf shop's website/app:\n",
    "\n",
    "User input (drop-down list):\n",
    "- Board Dimensions (height, width, thickness)\n",
    "- Condition (poor, fair, good, excellent, new)\n",
    "- Manufacturer\n",
    "- Model Name\n",
    "- Type of board (shortboard, longboard, SUP)\n",
    "- How many fixed dings are there? \n",
    "    - For each ding select size of ding:\n",
    "        - Small (<= 1 square inches)\n",
    "        - Medium (<= 6 square inches)\n",
    "        - Large (=> 6 square inches)\n",
    "- How many unfixed dings are there?\n",
    "\n",
    "Product Output: Predicted Surfboard Price (continous value)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
