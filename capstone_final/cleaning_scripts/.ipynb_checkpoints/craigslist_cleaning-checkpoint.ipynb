{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Options for pandas\n",
    "pd.options.display.max_columns = 150\n",
    "pd.options.display.max_rows = 150\n",
    "pd.options.display.max_colwidth = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Introduction</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Imports\" data-toc-modified-id=\"Imports-1.0.1\"><span class=\"toc-item-num\">1.0.1&nbsp;&nbsp;</span>Imports</a></span></li></ul></li></ul></li><li><span><a href=\"#Data-Cleaning:-Part-1-(Filtering)\" data-toc-modified-id=\"Data-Cleaning:-Part-1-(Filtering)-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Data Cleaning: Part 1 (Filtering)</a></span></li><li><span><a href=\"#Data-Cleaning:-Part-2-(Null-Values)\" data-toc-modified-id=\"Data-Cleaning:-Part-2-(Null-Values)-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Data Cleaning: Part 2 (Null Values)</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bay area\n",
    "https://sfbay.craigslist.org/search/sga?query=surfboard&sort=rel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('data/honolulu_craiglist_surfboards.json') as datafile:\n",
    "    data = json.load(datafile)\n",
    "hi_df = pd.DataFrame(data)\n",
    "\n",
    "with open('data/raw_data/los_angeles_craiglist_surfboards.json') as datafile:\n",
    "    data = json.load(datafile)\n",
    "la_df = pd.DataFrame(data)\n",
    "\n",
    "with open('data/raw_data/san_diego_craiglist_surfboards.json') as datafile:\n",
    "    data = json.load(datafile)\n",
    "sd_df = pd.DataFrame(data)\n",
    "\n",
    "df = hi_df.append([la_df,sd_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>condition</th>\n",
       "      <th>description</th>\n",
       "      <th>location</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>model_name</th>\n",
       "      <th>price</th>\n",
       "      <th>size_dimensions</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>\\n        \\nVery good condition wade tokoro shortboard surfboard, fcsii fin boxes, no dings, very little use\\n\\n5’8 x 19 x 2.25\\n\\nThank you\\n\\n\\n\\nSurfboards, surf board, boards, board, fins, fcs...</td>\n",
       "      <td>Honolulu</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>250.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tokoro surfboard</td>\n",
       "      <td>https://honolulu.craigslist.org/oah/spo/d/honolulu-tokoro-surfboard/7005760652.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>excellent</td>\n",
       "      <td>\\n        \\n6'2\"x20.5x2 prototype board from Eric Arakawa. made for an industry pro. Biaxial fiberglass. FCS boxes, thruster. Waist of the board is farther towards the tail making a fun board that...</td>\n",
       "      <td>Honolulu</td>\n",
       "      <td>Eric Arakawa</td>\n",
       "      <td>Prototype</td>\n",
       "      <td>180.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Arakawa Prototype Surfboard</td>\n",
       "      <td>https://honolulu.craigslist.org/oah/spo/d/wheeler-army-airfield-arakawa-prototype/7011893010.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>good</td>\n",
       "      <td>\\n        \\nAndreini surfboard. 6'6\". Large volume. Board had delam on top, it was repaired and sealed, but not filled/leveled with q-cell. Futures fin boxes in a tri/thruster. Cheap plastic fins ...</td>\n",
       "      <td>Honolulu</td>\n",
       "      <td>Andreini</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80.0</td>\n",
       "      <td>6'6\"x20\"x2\"</td>\n",
       "      <td>Andreini Surfboard</td>\n",
       "      <td>https://honolulu.craigslist.org/oah/spo/d/wheeler-army-airfield-andreini-surfboard/7011895192.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>good</td>\n",
       "      <td>\\n        \\n5’11 x 18.75 x 2.37 - 27.46L\\n\\nKrank model by J. Kashiwai. Squash tail w/ future box thruster setup.\\n\\nBoard is in decent to good condition. No open dings at all and still has a lot ...</td>\n",
       "      <td>Honolulu</td>\n",
       "      <td>Jason Kashiwai</td>\n",
       "      <td>Krank</td>\n",
       "      <td>250.0</td>\n",
       "      <td>5’11 x 18.75 x 2.37 = 27.46L</td>\n",
       "      <td>5’11 J. Kashiwai “Krank” Surfboard w/ Fins</td>\n",
       "      <td>https://honolulu.craigslist.org/oah/spo/d/honolulu-511-kashiwai-krank-surfboard/7011909978.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>\\n        \\n6' Egg Shortboard Surfboard with fins\\n\\nThe listed dimensions are 6’ x 19 3/4 x 2 3/4\\n\\n</td>\n",
       "      <td>Honolulu</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>220.0</td>\n",
       "      <td>6'</td>\n",
       "      <td>6' Egg Shortboard Surfboard</td>\n",
       "      <td>https://honolulu.craigslist.org/oah/spo/d/honolulu-6-egg-shortboard-surfboard/7011911532.html</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   condition  \\\n",
       "0        NaN   \n",
       "1  excellent   \n",
       "2       good   \n",
       "3       good   \n",
       "4        NaN   \n",
       "\n",
       "                                                                                                                                                                                               description  \\\n",
       "0  \\n        \\nVery good condition wade tokoro shortboard surfboard, fcsii fin boxes, no dings, very little use\\n\\n5’8 x 19 x 2.25\\n\\nThank you\\n\\n\\n\\nSurfboards, surf board, boards, board, fins, fcs...   \n",
       "1  \\n        \\n6'2\"x20.5x2 prototype board from Eric Arakawa. made for an industry pro. Biaxial fiberglass. FCS boxes, thruster. Waist of the board is farther towards the tail making a fun board that...   \n",
       "2  \\n        \\nAndreini surfboard. 6'6\". Large volume. Board had delam on top, it was repaired and sealed, but not filled/leveled with q-cell. Futures fin boxes in a tri/thruster. Cheap plastic fins ...   \n",
       "3  \\n        \\n5’11 x 18.75 x 2.37 - 27.46L\\n\\nKrank model by J. Kashiwai. Squash tail w/ future box thruster setup.\\n\\nBoard is in decent to good condition. No open dings at all and still has a lot ...   \n",
       "4                                                                                               \\n        \\n6' Egg Shortboard Surfboard with fins\\n\\nThe listed dimensions are 6’ x 19 3/4 x 2 3/4\\n\\n       \n",
       "\n",
       "   location    manufacturer model_name  price               size_dimensions  \\\n",
       "0  Honolulu             NaN        NaN  250.0                           NaN   \n",
       "1  Honolulu    Eric Arakawa  Prototype  180.0                           NaN   \n",
       "2  Honolulu        Andreini        NaN   80.0                   6'6\"x20\"x2\"   \n",
       "3  Honolulu  Jason Kashiwai      Krank  250.0  5’11 x 18.75 x 2.37 = 27.46L   \n",
       "4  Honolulu             NaN        NaN  220.0                            6'   \n",
       "\n",
       "                                        title  \\\n",
       "0                            Tokoro surfboard   \n",
       "1                 Arakawa Prototype Surfboard   \n",
       "2                          Andreini Surfboard   \n",
       "3  5’11 J. Kashiwai “Krank” Surfboard w/ Fins   \n",
       "4                 6' Egg Shortboard Surfboard   \n",
       "\n",
       "                                                                                                  url  \n",
       "0                 https://honolulu.craigslist.org/oah/spo/d/honolulu-tokoro-surfboard/7005760652.html  \n",
       "1   https://honolulu.craigslist.org/oah/spo/d/wheeler-army-airfield-arakawa-prototype/7011893010.html  \n",
       "2  https://honolulu.craigslist.org/oah/spo/d/wheeler-army-airfield-andreini-surfboard/7011895192.html  \n",
       "3     https://honolulu.craigslist.org/oah/spo/d/honolulu-511-kashiwai-krank-surfboard/7011909978.html  \n",
       "4       https://honolulu.craigslist.org/oah/spo/d/honolulu-6-egg-shortboard-surfboard/7011911532.html  "
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2781"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning: Part 1 (Filtering)\n",
    "Filter out:\n",
    "    - Duplicates ads\n",
    "    - Unrelated ads\n",
    "    - Single ad multiple products (e.g. multiple boards and/or includes fins, leashes, board bags etc.)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop duplicate ads\n",
    "df = df.drop_duplicates(subset=['description']).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    stripped_text = re.sub(r'\\\\n|\\n|[(),?.!@#$&*:\\/]', ' ', text).strip().lower()\n",
    "    clean_text = [word for word in stripped_text.split(' ') if word != '']\n",
    "    return clean_text\n",
    "\n",
    "def ngram(text, n_gram):\n",
    "    n_gram_list = []\n",
    "    for i in range(len(text)-n_gram):\n",
    "        text_seq = ' '.join(text[i:i+n_gram])\n",
    "        if text_seq not in n_gram_list:\n",
    "            n_gram_list.append(text_seq)\n",
    "    return n_gram_list\n",
    "\n",
    "def one_board_filter(text, title=False):\n",
    "    multiple_products_words = ['boards', 'surfboards']\n",
    "    multiple_boards = 0\n",
    "    surfboard_in_title = 0\n",
    "    \n",
    "    if title == True:\n",
    "        surfboard_word_list = ['surfboard', 'surf', 'board', 'sup', 'fish', 'stub', 'shortboard', 'short', \n",
    "                                   'longboard', 'long', 'foamie', 'foam', 'softtop', 'paddleboard']\n",
    "        for word in text:\n",
    "            if word in multiple_products_words:\n",
    "                multiple_boards = 1\n",
    "            \n",
    "            elif word in surfboard_word_list:\n",
    "                surfboard_in_title = 1\n",
    "        \n",
    "        if multiple_boards == 1 or surfboard_in_title == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1\n",
    "    \n",
    "    else:\n",
    "        multiple_products = 0\n",
    "        for word in text:\n",
    "            if word in multiple_products_words:\n",
    "                multiple_products = 1\n",
    "        if multiple_products == 1:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1\n",
    "        \n",
    "def bigram_multiple_products_filter(bigram_list):\n",
    "    bigram_count = 0\n",
    "    bigram_check_list = ['does include', 'does includes', 'will include', 'are included', 'are including', 'is included', \n",
    "                    'is including', 'is with','come with', 'comes with']\n",
    "    \n",
    "    for bigram in bigram_list:\n",
    "        if bigram in bigram_check_list:\n",
    "            bigram_count += 1\n",
    "    if bigram_count >= 1:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create clean description and title word list columns to be used for filtering rows\n",
    "df['description_word_list'] = df['description'].apply(lambda x: clean_text(x))\n",
    "df['title_word_list'] = df['title'].apply(lambda x: clean_text(x))\n",
    "\n",
    "# filter out rows that include multiple boards/products\n",
    "df['one_board_description'] = df['description_word_list'].apply(lambda x: one_board_filter(x))\n",
    "df['one_board_title'] = df['title_word_list'].apply(lambda x: one_board_filter(x, title=True))\n",
    "\n",
    "df['bigram_description_list'] = df['description_word_list'].apply(lambda x: ngram(x, 2))\n",
    "df['bigram_one_board_description'] = df['bigram_description_list'].apply(lambda x: bigram_multiple_products_filter(x))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = df.loc[(df['one_board_description'] == 1) & (df['one_board_title'] == 1) \n",
    "            & (df['bigram_one_board_description'] == 1)].copy()\n",
    "\n",
    "df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning: Part 2 (Null Values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index                            0.000000\n",
       "condition                       51.280120\n",
       "description                      0.000000\n",
       "location                         0.000000\n",
       "manufacturer                    52.635542\n",
       "model_name                      67.771084\n",
       "price                            0.000000\n",
       "size_dimensions                 61.897590\n",
       "title                            0.000000\n",
       "url                              0.000000\n",
       "description_word_list            0.000000\n",
       "title_word_list                  0.000000\n",
       "one_board_description            0.000000\n",
       "one_board_title                  0.000000\n",
       "bigram_description_list          0.000000\n",
       "bigram_one_board_description     0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()/df.isnull().count()*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngram_condition_filter(text, ngram=2):\n",
    "    condition_list = ['new', 'excellent', 'good', 'like new', 'fair', 'great', 'perfect', 'decent', 'pristine', 'mint',\n",
    "                  'poor']\n",
    "    bigram_list = ['in condition', 'very condition', 'like condition', 'in shape', 'surfboard condition', 'a hybrid', \n",
    "               'a board', 'near condition', 'board condition', 'in working', 'brand carbon', 'really condition', \n",
    "               'almost condition', '- condition', 'very quality', 'sale condition', 'condition', 'used condition', \n",
    "               'really shape', 'nearly condition', 'absolute condition', 'out condition']\n",
    "    \n",
    "    unigram_list = ['brand', 'like']\n",
    "\n",
    "    for i,word in enumerate(text):\n",
    "        if word in condition_list:\n",
    "            if ' '.join(text[i-(ngram-1):i+ngram:ngram]) in bigram_list or text[i-1] in unigram_list:\n",
    "                return word\n",
    "\n",
    "\n",
    "def remove_secondary_words(text_list, secondary_list):\n",
    "    primary_words = [word for word in text_list if word not in secondary_list]\n",
    "    return primary_words\n",
    "\n",
    "def extract_model_manufacturer(text_list, match_list):\n",
    "    extracted_text = [word for word in text_list if word in match_list]\n",
    "    return extracted_text\n",
    "\n",
    "def motorola_filter(text_list):\n",
    "    for word in text_list:\n",
    "        if word == 'motorola':\n",
    "            return 1\n",
    "        else:\n",
    "            continue\n",
    "    return 0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['condition_from_description'] = df['description_word_list'].apply(lambda x: ngram_condition_filter(x))\n",
    "\n",
    "#replace nulls in condition with condition extracted from description\n",
    "df.loc[df['condition'].isnull(),'condition'] = df['condition_from_description']\n",
    "\n",
    "#create separate columns for each board measurement\n",
    "# df['length'] =  df['size_dimensions'].apply(lambda x: extract_board_dimension(x, length_pattern))\n",
    "# df['width'] =  df['size_dimensions'].apply(lambda x: extract_board_dimension(x, width_pattern))\n",
    "# df['thickness'] =  df['size_dimensions'].apply(lambda x: extract_board_dimension(x, thickness_pattern))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # words likely to have a strong negative correlatation with price\n",
    "# one_hot_word_list = ['ding', 'dings', 'yellow', 'patched', 'patch', 'repaired', 'fixed', 'fix', 'carbon',\n",
    "#                      'fiber', 'pressure', 'dent', 'old', 'salvage', 'crack', 'cracks', 'epoxy', 'foamie', \n",
    "#                      'foam', 'softtop', 'longboard', 'shortboard', 'sup']\n",
    "# description_dummy_cols = []\n",
    "\n",
    "# df.reset_index(inplace=True)\n",
    "# for word in one_hot_word_list:\n",
    "#     #init one-hot columns\n",
    "#     df['DV_'+word] = 0\n",
    "#     description_dummy_cols.append('DV_'+word)\n",
    "    \n",
    "# for i,word_list in enumerate(df['description_word_list']):\n",
    "#     for word in one_hot_word_list:\n",
    "#         if word in word_list:\n",
    "#             df.at[i, 'DV_'+word] = 1\n",
    "#         else: \n",
    "#             df.at[i, 'DV_'+word] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "secondary_list = ['surfboard', 'surfboards', 'surf', 'board', 'boards', 'longboard', 'longboards', 'shortboard', \n",
    "                  'shortboards' 'softop', 'design', 'designs', 'shape', 'shaper', 'shapes', 'model', 'serie', 'series',\n",
    "                  'version', 'type', 'vintage', 'by', 'the', 'and', 'or', 'shop', 'on', 'up', 'company']\n",
    "\n",
    "df['manufacturer_word_list'] = df['manufacturer'].astype(str).apply(lambda x: remove_secondary_words(clean_text(x),\n",
    "                                                                  secondary_list))\n",
    "df['model_name_word_list'] = df['model_name'].astype(str).apply(lambda x: remove_secondary_words(clean_text(x),\n",
    "                                                                  secondary_list))\n",
    "\n",
    "df['is_motorola'] = df['manufacturer_word_list'].apply(lambda x: motorola_filter(x))\n",
    "\n",
    "df = df[df['is_motorola'] == 0].copy()\n",
    "\n",
    "manufacturer_list = np.unique([word for word_list in df['manufacturer_word_list'].tolist() for word in word_list])\n",
    "model_name_list = np.unique([word for word_list in df['model_name_word_list'].tolist() for word in word_list])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['manufacturer_from_description'] = df['description_word_list'].apply(lambda x: extract_model_manufacturer(x, manufacturer_list))\n",
    "\n",
    "df['model_name_from_description'] = df['description_word_list'].apply(lambda x: extract_model_manufacturer(x, model_name_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22, 625]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "84.5"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_board_dimension(text, pattern):\n",
    "    try:\n",
    "        raw_dimension = pattern.findall(text)[0]\n",
    "    except (IndexError, TypeError):\n",
    "        return np.NaN\n",
    "    int_dimension = list(map(int, re.findall('\\d+', raw_dimension)))\n",
    "    print(int_dimension)\n",
    "    \n",
    "    #str dimension includes fraction\n",
    "    if len(int_dimension) == 3:\n",
    "        return int_dimension[0] + (int_dimension[1]/int_dimension[2])\n",
    "    elif len(int_dimension) == 2:\n",
    "        return int_dimension[0] + (int_dimension[1] / 10)\n",
    "    else:\n",
    "        return int_dimension[0]\n",
    "    \n",
    "\n",
    "length_pattern = re.compile('(?<![Xx\\d+\\\"])\\d+[\\u0080-\\uFFFF\\'\\.]\\d+(?=[\\\"\\s*Xx])')\n",
    "width_pattern = re.compile('(?<=[Xx])\\s?\\d+[\\\"/s*\\.]?\\s?\\d?[\\\"\\/]?\\d+?(?=[\\s?\\\"Xx?])')\n",
    "thickness_pattern = re.compile('(?<=[Xx?])\\s?\\d+[\\\"/s*\\.]?\\s?\\d+?[\\\"\\/]?\\d+?(?=[\\\",]?)(?![\\dXx])')\n",
    "                    \n",
    "text = \"\"\"9'-0\" x 22.625\" x 2.625\" \"\"\"\n",
    "extract_board_dimension(text, width_pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('great', 49),\n",
       " ('perfect', 11),\n",
       " ('decent', 5),\n",
       " ('fun', 4),\n",
       " ('sick', 2),\n",
       " ('solid', 2),\n",
       " ('mint', 2),\n",
       " ('short', 2),\n",
       " ('used', 2),\n",
       " ('begginers', 2),\n",
       " ('large', 2),\n",
       " ('one', 2),\n",
       " ('real', 1),\n",
       " ('best', 1),\n",
       " ('rough', 1),\n",
       " ('step-up', 1),\n",
       " ('obo', 1),\n",
       " ('fast', 1),\n",
       " ('awesome', 1),\n",
       " ('larger', 1),\n",
       " ('new)', 1),\n",
       " ('shorter', 1),\n",
       " ('vintage', 1),\n",
       " ('repaired', 1),\n",
       " ('as-is', 1),\n",
       " ('padded', 1),\n",
       " ('seaworthy', 1),\n",
       " (\"7'\", 1),\n",
       " ('surfable', 1),\n",
       " ('foil', 1),\n",
       " ('v-cluster', 1),\n",
       " ('poor', 1),\n",
       " ('and', 1),\n",
       " ('excelelnt', 1),\n",
       " ('small', 1),\n",
       " ('unique', 1),\n",
       " ('nice', 1),\n",
       " ('surfboard', 1),\n",
       " ('midsize', 1),\n",
       " ('excelent', 1),\n",
       " ('loose', 1),\n",
       " ('infinity', 1),\n",
       " ('every', 1),\n",
       " ('cool', 1),\n",
       " ('them)', 1),\n",
       " ('hp', 1),\n",
       " ('conventional', 1),\n",
       " ('grom', 1),\n",
       " ('usable', 1),\n",
       " ('surf', 1)]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_list = ['in condition', 'very condition', 'brand never', 'like condition', 'in shape', 'surfboard condition', \n",
    "              'a hybrid', 'brand surfboard', 'brand condition', 'a board', 'near condition', 'board condition', \n",
    "               'brand board', 'in working', 'brand carbon', 'brand sup', 'really condition', 'like no', 'like used',\n",
    "              'like only', 'almost condition', 'brand for', 'brand beautiful', 'like i', 'brand js', 'like', '- condition',\n",
    "              'very quality', 'brand -', 'like in', 'brand only', 'brand quality', 'brand kazuma', 'sale condition', \n",
    "              'condition', 'used condition', 'brand save', 'like and', 'brand check', 'brand performance', 'really shape',\n",
    "              '(like condition)', 'brand it']\n",
    "condition_list = ['new', 'excellent', 'good', 'like new', 'fair']\n",
    "not_condition_list = []\n",
    "for text in df['description_word_list']:\n",
    "    for i,word in enumerate(text):\n",
    "        if ' '.join(text[i-1:i+2:2]) in bigram_list and word not in condition_list:\n",
    "            not_condition_list.append(word)\n",
    "            \n",
    "Counter(not_condition_list).most_common()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "combine like new and excellent into one condition\n",
    "\n",
    "look for other conditions that are similar to condition list\n",
    "\n",
    "outliers for price possibly multiple boards or look in description for plural board words\n",
    "\n",
    "create filters for description to weed out guranteed noise (len of description)\n",
    "\n",
    "scrape other sites\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "good         261\n",
       "new          218\n",
       "like new     186\n",
       "fair          58\n",
       "great         24\n",
       "excellent      2\n",
       "perfect        2\n",
       "mint           1\n",
       "Name: condition, dtype: int64"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['condition'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_map_dict = {'new': 'new',\n",
    "                      'perfect': 'new',\n",
    "                      'pristine': 'like new',\n",
    "                      'excellent': 'like new',\n",
    "                      'mint': 'like new',\n",
    "                      'great': 'great',\n",
    "                      'good': 'good',\n",
    "                      'fair': 'fair',\n",
    "                      'decent': 'fair',\n",
    "                      'poor': 'poor'}\n",
    "df['condition'] = df['condition'].map(condition_map_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "good        261\n",
       "new         220\n",
       "fair         58\n",
       "great        24\n",
       "like new      3\n",
       "Name: condition, dtype: int64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['condition'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# condition_list = ['new', 'excellent', 'good', 'like new', 'fair', 'great', 'perfect', 'decent', 'pristine', 'mint',\n",
    "#                   'poor']\n",
    "# all_bigrams = []\n",
    "\n",
    "# for i,text in enumerate(df['description_word_list']):\n",
    "#     for i,word in enumerate(text):\n",
    "#         if word in condition_list:\n",
    "#             all_bigrams.append(' '.join(text[i-1:i+2:2]))\n",
    "\n",
    "# dict(Counter(all_bigrams).most_common())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.surfstationstore.com/collections/used-surfboards\n",
    "\n",
    "https://www.usedsurfboardshawaii.com/?post_type=product \n",
    "\n",
    "combine all clean df into one and predict price together\n",
    "\n",
    "To do:\n",
    "\n",
    "get more data (~2500 rows)\n",
    "\n",
    "clean data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "extract indiv dimensions as indiv col from dimen col\n",
    "if nan after extract from description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df = df.dropna(subset=['condition', 'dimensions'], how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = df[df['surfboard_in_title']==1].copy()\n",
    "test_data = test_data.dropna(how='any')\n",
    "\n",
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_df = pd.get_dummies(test_data[['condition','manufacturer', 'model_name']])\n",
    "data_x = pd.merge(one_hot_df, test_data[description_dummy_cols], how='inner', left_on=one_hot_df.index, right_on=test_data.index)\n",
    "data_y = test_data['price']\n",
    "\n",
    "data_x = data_x.loc[:, data_x.columns != 'key_0']\n",
    "\n",
    "len(data_x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
