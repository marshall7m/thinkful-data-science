{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Introduction</a></span></li><li><span><a href=\"#Imports\" data-toc-modified-id=\"Imports-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Imports</a></span></li><li><span><a href=\"#EDA\" data-toc-modified-id=\"EDA-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>EDA</a></span><ul class=\"toc-item\"><li><span><a href=\"#Data-Cleaning\" data-toc-modified-id=\"Data-Cleaning-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Data Cleaning</a></span></li></ul></li><li><span><a href=\"#Modeling\" data-toc-modified-id=\"Modeling-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Modeling</a></span><ul class=\"toc-item\"><li><span><a href=\"#Main-Label\" data-toc-modified-id=\"Main-Label-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Main Label</a></span></li><li><span><a href=\"#Location-Label\" data-toc-modified-id=\"Location-Label-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Location Label</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a multi-layer perceptron neural network model to predict on a labeled dataset of your choosing. Compare this model to either a boosted tree or a random forest model and describe the relative tradeoffs between complexity and accuracy. Be sure to vary the hyperparameters of your MLP!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import ensemble\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import time\n",
    "\n",
    "import operator\n",
    "import os\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Options for pandas\n",
    "pd.options.display.max_columns = 100\n",
    "pd.options.display.max_rows = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "user2 = pd.read_csv('data/user2.features_labels.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use linear interpolate with grouped label?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general function used to clean dataframes. \n",
    "\n",
    "def clean_df(df, main_labels, loc_labels, secondary_labels, interpolate='linear'):\n",
    "    \n",
    "    label_col = [col for col in list(df.columns) if col[:6] == 'label:']\n",
    "    \n",
    "    for col in label_col:\n",
    "        df[col].fillna(0, axis=0, inplace=True)\n",
    "\n",
    "    #drop observations with no labels\n",
    "    no_label_index = list(df[df[label_col].eq(0).all(1)].index)\n",
    "\n",
    "    df.drop(df.index[no_label_index], axis=0, inplace=True)\n",
    "\n",
    "    #drop all columns where all observations are nans\n",
    "    drop_col = df.loc[:, df.isnull().sum()/df.isnull().count()*100 == 100].columns\n",
    "    df.drop(drop_col, axis=1, inplace=True)\n",
    "    \n",
    "    #interpolate\n",
    "    nan_col = [col for col in list(df.columns) if df[col].isnull().sum()/df[col].isnull().count()*100 > 0]\n",
    "\n",
    "    for col in nan_col:\n",
    "        df[col].interpolate(method='linear', limit_direction='both', inplace=True)\n",
    "    \n",
    "    #dictionary that separates labels by categories\n",
    "    label_dict = {'main_label': main_labels, 'loc_label': loc_labels, 'secondary_label': secondary_labels}\n",
    "    \n",
    "    #finds labels that fall under each label category above and adds it to new column relating to label category.\n",
    "    for label, lst in label_dict.items():\n",
    "        #init dict\n",
    "        df_label_dict = {i: '' for i in range(len(df))}\n",
    "        # add labels to dict if labels is present in respective index\n",
    "        for i in range(len(df)):\n",
    "            for col in lst:\n",
    "                if df[col].iloc[i] == 1:\n",
    "                    #creates multiclass label\n",
    "                    df_label_dict[i] += col + ' '\n",
    "        df[label] = pd.Series(df_label_dict).apply(lambda x: x if x != '' else np.NaN)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_col = label_col = [col for col in list(user1.columns) if col[:6] == 'label:']\n",
    "\n",
    "main_labels = ['label:LYING_DOWN', 'label:SITTING', 'label:FIX_running', 'label:OR_standing','label:SLEEPING', \n",
    "               'label:FIX_walking']\n",
    "\n",
    "loc_labels = ['label:LAB_WORK', 'label:IN_CLASS', 'label:IN_A_MEETING', 'label:LOC_main_workplace','label:OR_indoors',\n",
    " 'label:OR_outside', 'label:IN_A_CAR', 'label:ON_A_BUS', 'label:LOC_home', 'label:FIX_restaurant','label:SHOPPING',\n",
    "'label:AT_A_PARTY', 'label:AT_A_BAR', 'label:LOC_beach', 'label:AT_THE_GYM', 'label:ELEVATOR', 'label:AT_SCHOOL']\n",
    "\n",
    "not_secondary_labels = main_labels + loc_labels\n",
    "secondary_labels = [col for col in label_col if col not in not_secondary_labels]\n",
    "\n",
    "user2 = clean_df(user2, main_labels, loc_labels, secondary_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_features_list = label_col + ['timestamp', 'label_source', 'main_label', 'loc_label', 'secondary_label', 'timestamp' ]\n",
    "all_feature_list = [col for col in list(user2.columns) if col not in not_features_list]\n",
    "\n",
    "def predict_label(user, model_dict, feature_list, label):\n",
    "    data = user[user[label] != '']\n",
    "    data = data.dropna(subset=[label])\n",
    "\n",
    "    train_x, test_x, train_y, test_y = train_test_split(data[feature_list], data[label], test_size=.3)\n",
    "    print(train_x.shape)\n",
    "    print(len(test_y.unique()))\n",
    "    for name,model in model_dict.items():\n",
    "        start_time = time.time()\n",
    "        model.fit(train_x, train_y)\n",
    "        end_time = time.time()\n",
    "        score = model.score(test_x, test_y)\n",
    "        print()\n",
    "        print('{} accuracy: {}'.format(name, score))\n",
    "        print('Runtime: ', end_time - start_time)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "hide_input": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3259, 220)\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marshallmamiya/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "rfc accuracy: 0.9163090128755365\n",
      "Runtime:  0.2814369201660156\n",
      "\n",
      "mlp accuracy: 0.8197424892703863\n",
      "Runtime:  7.413454055786133\n"
     ]
    }
   ],
   "source": [
    "rfc = ensemble.RandomForestClassifier()\n",
    "hidden_sizes = [150]\n",
    "mlp = MLPClassifier(hidden_layer_sizes=hidden_sizes, alpha=.0001, learning_rate_init=.001, solver='adam',\n",
    "                    activation='logistic')\n",
    "\n",
    "model_dict = {'rfc': rfc, 'mlp': mlp}\n",
    "\n",
    "main_model_dict = predict_label(user2, model_dict, all_feature_list, 'main_label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Location Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4448, 220)\n",
      "11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marshallmamiya/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "rfc accuracy: 0.9124278972207656\n",
      "Runtime:  0.42943406105041504\n",
      "\n",
      "mlp accuracy: 0.7477713686418458\n",
      "Runtime:  12.490822076797485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marshallmamiya/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "rfc = ensemble.RandomForestClassifier()\n",
    "hidden_sizes = [150]\n",
    "mlp = MLPClassifier(hidden_layer_sizes=hidden_sizes, alpha=.0001, learning_rate_init=.001, solver='adam',\n",
    "                    activation='logistic')\n",
    "\n",
    "model_dict = {'rfc': rfc, 'mlp': mlp}\n",
    "\n",
    "main_model_dict = predict_label(user2, model_dict, all_feature_list, 'loc_label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the small amount of training data and moderate amount of features, one hidden layer was appropriate. Using half of the input size as the hidden layer size had the best accuracy results. Since this is a classification problem, logistic sigmoid activate function was used to transform the output to a number between 0-1. The output represents the predicted probability for each target class/label.\n",
    "\n",
    "Compared to the Random Forrest Classifier (RFC) with default parameters, the Multi-Layer Perceptron (MLP) under performed even after hyper-parameters tuning. In addition, the runtime for MLP was much larger comapred to the RFC. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
